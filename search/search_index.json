{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#change-point-detection-based-on-online-dmd-with-control","title":"Change-Point Detection based on Online DMD with Control","text":"<p>As the energy sector races toward radical climate action, scaling new solutions is essential. Automated control has been crucial to efficient operations, and detecting unforeseen critical shifts can be a game-changer for safety.</p> <p></p> <p>This repository presents a novel approach to change-point detection (CPD) that leverages Online Dynamic Mode Decomposition with Control (ODMDwC). Designed specifically for complex industrial systems where timely detection of behavioral shifts is critical, this method captures both spatial and temporal system patterns and adapts dynamically to non-linear system changes due to factors like aging and seasonality.</p> <p>Our ODMDwC-based method addresses real-world challenges of non-uniform data streams in safety-critical systems by providing reliable CPD without dependency on exhaustive physical models. It leverages control input to enhance change detection performance, yielding robust and intuitive results even in environments with high noise.</p>"},{"location":"#features","title":"\ud83d\ude80 Features","text":"<ul> <li>Adaptive Linearization: ODMDwC dynamically adapts to system behavior, maintaining a correspondence between detected changes and their actual extent.</li> <li>Truncated ODMDwC with Time-Delay Embeddings: Incorporates higher-order time-delay embeddings to improve noise robustness and capture broadband features.</li> <li>Enhanced CPD Performance: The method outperforms SVD-based and other common CPD methods on benchmark datasets, improving detection accuracy while reducing false positives.</li> <li>Intuitive Hyperparameter Tuning: Offers practical guidelines for hyperparameter selection to streamline model application.</li> </ul>"},{"location":"#benchmark-evaluation","title":"Benchmark Evaluation","text":"<p>We validated our approach on both synthetic and real-world datasets, including:</p> <ol> <li> <p>SKAB Laboratory Water Circulation System</p> Algorithm NAB (standard) NAB (low FP) NAB (low FN) Perfect detector 54.77 54.11 56.99 CPD-DMD (\\(t=0\\)) 34.29 23.21 42.54 CPD-DMD (\\(t=0.0025\\)) 33.43 23.28 41.71 MSCRED 32.42 16.53 40.28 Isolation forest 26.16 19.50 30.82 T-squared+Q (PCA) 25.35 14.51 31.33 Conv-AE 23.61 21.54 27.55 LSTM-AE 23.51 20.11 25.91 T-squared 19.54 10.20 24.31 MSET 13.84 10.22 17.37 Vanilla AE 11.41 6.53 13.91 Vanilla LSTM 11.31 -3.80 17.25 Null detector 0.00 0.00 0.00 </li> <li> <p>CATS Controlled Anomalies Dataset</p> Algorithm NAB (standard) NAB (low FP) NAB (low FN) Perfect detector 30.21 29.89 31.28 MSCRED 37.19 13.46 47.18 CPD-DMD (\\(t=0\\)) 25.66 20.62 29.84 CPD-DMD 17.84 15.01 20.06 Isolation forest (\\(c=3.8\\%\\)) 17.81 15.84 20.00 T-squared+Q (PCA) 11.80 11.40 12.30 LSTM-AE 11.39 11.26 11.69 T-squared 15.15 14.98 15.71 MSET 14.48 13.43 15.60 Vanilla AE 2.52 2.44 2.77 Vanilla LSTM 0.73 0.70 0.82 Conv-AE 0.15 0.14 0.18 Null detector 0.00 0.00 0.00 </li> </ol>"},{"location":"#citation","title":"\ud83d\udcdc Citation","text":"<p>If you use this platform for academic purposes, please cite our publication:</p> <pre><code>@misc{wadinger2024changepointdetectionindustrialdata,\n    author    ={Marek Wadinger and Michal Kvasnica and Yoshinobu Kawahara},\n    note      = {Submitted to Applied Energy},\n    title     ={Change-Point Detection in Industrial Data Streams based on Online Dynamic Mode Decomposition with Control},\n    url       ={https://arxiv.org/abs/2407.05976},\n    year      ={2024},\n}\n</code></pre>"},{"location":"#contributing","title":"\ud83d\udc50 Contributing","text":"<p>Feel free to contribute in any way you like, we're always open to new ideas and approaches.</p> <ul> <li>Feel welcome to open an issue if you think you've spotted a bug or a performance issue.</li> </ul>"},{"location":"#for-developers","title":"\ud83d\udee0 For Developers","text":""},{"location":"#installation-for-local-use","title":"Installation (for Local Use)","text":"<p>If you wish to run the platform locally, follow the steps below:</p> <ol> <li> <p>Clone the repository:</p> <pre><code>git clone https://github.com/MarekWadinger/odmd-subid-cpd.git\n</code></pre> </li> <li> <p>Navigate to the project folder:</p> <pre><code>cd odmd-subid-cpd\n</code></pre> </li> <li> <p>Create a virtual environment:</p> <pre><code>python -m venv --upgrade-deps .venv\nsource .venv/bin/activate\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>functions<ul> <li>bayes_opt_parallel</li> <li>chdsubid</li> <li>datasets</li> <li>dmd</li> <li>metrics</li> <li>plot</li> <li>preprocessing</li> <li>rolling</li> </ul> </li> </ul>"},{"location":"reference/functions/","title":"Index","text":""},{"location":"reference/functions/#functions","title":"functions","text":"<p>Modules:</p> <ul> <li> <code>bayes_opt_parallel</code>           \u2013            </li> <li> <code>chdsubid</code>           \u2013            <p>Change Detection based on Subspace Identification algorithm.</p> </li> <li> <code>dmd</code>           \u2013            <p>Dynamic Mode Decomposition (DMD) in scikkit-learn API.</p> </li> <li> <code>metrics</code>           \u2013            <p>This module is modified part of evaluation from library tsad</p> </li> <li> <code>plot</code>           \u2013            </li> <li> <code>preprocessing</code>           \u2013            </li> <li> <code>rolling</code>           \u2013            </li> </ul>"},{"location":"reference/functions/bayes_opt_parallel/","title":"bayes_opt_parallel","text":""},{"location":"reference/functions/bayes_opt_parallel/#functions.bayes_opt_parallel","title":"bayes_opt_parallel","text":"<p>Classes:</p> <ul> <li> <code>BayesianOptimizationHandler</code>           \u2013            <p>Basic functionality for NLP handlers.</p> </li> </ul>"},{"location":"reference/functions/bayes_opt_parallel/#functions.bayes_opt_parallel.BayesianOptimizationHandler","title":"BayesianOptimizationHandler","text":"<p>               Bases: <code>RequestHandler</code></p> <p>Basic functionality for NLP handlers.</p>"},{"location":"reference/functions/chdsubid/","title":"chdsubid","text":""},{"location":"reference/functions/chdsubid/#functions.chdsubid","title":"chdsubid","text":"<p>Change Detection based on Subspace Identification algorithm.</p> <p>Classes:</p> <ul> <li> <code>DMDChangeDetector</code>           \u2013            <p>Change-Point Detection on Subspace Identification with Online DMD.</p> </li> <li> <code>SubIDChangeDetector</code>           \u2013            <p>Change-Point Detection on Subspace Identification.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>get_default_params</code>             \u2013              <p>Get default parameters for the given dataset and window size</p> </li> <li> <code>get_default_rank</code>             \u2013              <p>Get default rank for the given data matrix</p> </li> </ul>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.DMDChangeDetector","title":"DMDChangeDetector","text":"<pre><code>DMDChangeDetector(\n    subid: OnlineDMD | OnlineDMDwC | Rolling,\n    ref_size: int,\n    test_size: int | None = None,\n    threshold: float = 0.25,\n    lag: int = 0,\n    grace_period: int = 0,\n    learn_after_grace: bool = True,\n)\n</code></pre> <p>               Bases: <code>SubIDChangeDetector</code></p> <p>Change-Point Detection on Subspace Identification with Online DMD.</p> <p>This class implements is optimized for the OnlineDMD and OnlineDMDwC classes, where computation of eigenvalues during transformation creates a bottleneck. It stores transformed data and only recomputes the transformation when the Koopman operator changes.</p> <p>The computation time is approx. 20% lower for the OnlineDMD (80 features). This has however, impact on the overall performance and adds positive trand in D_train - D_test score.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>learn_one</code>             \u2013              <p>Allias for update method for interoperability with Pipeline.</p> </li> </ul>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.DMDChangeDetector(SubIDChangeDetector)","title":"<code>SubIDChangeDetector</code>","text":"(<code>_type_</code>)           \u2013            <p>description</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.DMDChangeDetector.learn_one","title":"learn_one","text":"<pre><code>learn_one(x: dict, **params) -&gt; None\n</code></pre> <p>Allias for update method for interoperability with Pipeline.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector","title":"SubIDChangeDetector","text":"<pre><code>SubIDChangeDetector(\n    subid: MiniBatchTransformer | Transformer | Rolling,\n    ref_size: int,\n    test_size: int | None = None,\n    threshold: float = 0.25,\n    lag: int = 0,\n    grace_period: int = 0,\n    learn_after_grace: bool = True,\n    start_soon: bool = False,\n)\n</code></pre> <p>               Bases: <code>AnomalyDetector</code></p> <p>Change-Point Detection on Subspace Identification.</p> <p>This class implements a change-point detection algorithm based on subspace identification. It uses a subspace identification algorithm to transform the data and then computes the distance between the original data and the transformed data. The distance is then used to detect changes in the data distribution.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>learn_one</code>             \u2013              <p>Allias for update method for interoperability with Pipeline.</p> </li> </ul>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(subid)","title":"<code>subid</code>","text":"(<code>MiniBatchTransformer | Transformer | Rolling</code>)           \u2013            <p>Subspace identification algorithm</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(ref_size)","title":"<code>ref_size</code>","text":"(<code>int</code>)           \u2013            <p>Size of the reference window</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(test_size)","title":"<code>test_size</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Size of the test window. Defaults to None -&gt; ref_size.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(threshold)","title":"<code>threshold</code>","text":"(<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>Detection threshold. Defaults to 0.25.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(lag)","title":"<code>lag</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Time lag. Defaults to 0.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(grace_period)","title":"<code>grace_period</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Grace period. Defaults to 0.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(learn_after_grace)","title":"<code>learn_after_grace</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Learn after grace period. Defaults to True.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(start_soon)","title":"<code>start_soon</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Start detection as soon as possible. Defaults to False.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(True)","title":"<code>True</code>","text":"(<code>test</code>)           \u2013            <p>o, ref: x, both: w, none: .): 3: www      (started) 4: xwwo 5: xxwoo 6: xxxooo 7: xxx.ooo 8: .xxx.ooo</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector(False)","title":"<code>False</code>","text":"(<code>test</code>)           \u2013            <p>o, ref: x, both: w, none: .): 3: ooo 4: .ooo 5: x.ooo 6: xx.ooo 7: xxx.ooo  (started) 8: .xxx.ooo</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.SubIDChangeDetector.learn_one","title":"learn_one","text":"<pre><code>learn_one(x: dict, **params) -&gt; None\n</code></pre> <p>Allias for update method for interoperability with Pipeline.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.get_default_params","title":"get_default_params","text":"<pre><code>get_default_params(\n    X, U=None, window_size: int = 0, max_rank=10\n)\n</code></pre> <p>Get default parameters for the given dataset and window size Args:     X (np.ndarray): Data matrix     window_size (int): Window size. What kind of structural changes are we looking for?</p> References <p>[2] Moskvina, V., &amp; Zhigljavsky, A. (2003). An Algorithm Based on Singular Spectrum Analysis for Change-Point Detection. Communications in Statistics - Simulation and Computation, 32(2), 319-352. doi:10.1081/SAC-120017494.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.get_default_rank","title":"get_default_rank","text":"<pre><code>get_default_rank(X, noise_variance: float | None = None)\n</code></pre> <p>Get default rank for the given data matrix</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>int</code>          \u2013            <p>Default rank</p> </li> </ul> References <p>[1] Gavish, M., and Donoho L. D. (2014). The Optimal Hard Threshold for Singular Values is 4/sqrt(3). IEEE Transactions on Information Theory 60.8 (2014): 5040-5053. doi:10.1109/TIT.2014.2323359.</p>"},{"location":"reference/functions/chdsubid/#functions.chdsubid.get_default_rank(X)","title":"<code>X</code>","text":"(<code>ndarray</code>)           \u2013            <p>Data matrix</p>"},{"location":"reference/functions/datasets/","title":"datasets","text":""},{"location":"reference/functions/datasets/#functions.datasets","title":"datasets","text":""},{"location":"reference/functions/dmd/","title":"dmd","text":""},{"location":"reference/functions/dmd/#functions.dmd","title":"dmd","text":"<p>Dynamic Mode Decomposition (DMD) in scikkit-learn API.</p> <p>This module contains the implementation of the Online DMD, Windowed DMD, and DMD with Control algorithm. It is based on the paper by Zhang et al. [^1] and implementation of authors available at GitHub. However, this implementation provides a more flexible interface aligned with River API covers and separates update and revert methods in Windowed DMD.</p> <p>TODO:</p> <pre><code>- [ ] Align design with (n, m) convention (currently (m, n)).\n</code></pre> References <ol> <li> <p>Schmid, P. (2022). Dynamic Mode Decomposition and Its Variants. 54(1), pp.225-254. doi:10.1146/annurev-fluid-030121-015835.\u00a0\u21a9</p> </li> </ol> <p>Classes:</p> <ul> <li> <code>DMD</code>           \u2013            <p>Class for Dynamic Mode Decomposition (DMD) model.</p> </li> <li> <code>DMDwC</code>           \u2013            </li> </ul>"},{"location":"reference/functions/dmd/#functions.dmd.DMD","title":"DMD","text":"<pre><code>DMD(r: int = 0)\n</code></pre> <p>Class for Dynamic Mode Decomposition (DMD) model.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>m</code>               (<code>int</code>)           \u2013            <p>Number of features (variables).</p> </li> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>Number of time steps (snapshots).</p> </li> <li> <code>feature_names_in_</code>               (<code>list[str]</code>)           \u2013            <p>list of feature names. Used for pd.DataFrame inputs.</p> </li> <li> <code>Lambda</code>               (<code>ndarray</code>)           \u2013            <p>Eigenvalues of the Koopman matrix.</p> </li> <li> <code>Phi</code>               (<code>ndarray</code>)           \u2013            <p>Eigenfunctions of the Koopman operator (Modal structures)</p> </li> <li> <code>A_bar</code>               (<code>ndarray</code>)           \u2013            <p>Low-rank approximation of the Koopman operator (Rayleigh quotient matrix).</p> </li> <li> <code>A</code>               (<code>ndarray</code>)           \u2013            <p>Koopman operator.</p> </li> <li> <code>C</code>               (<code>ndarray</code>)           \u2013            <p>Discrete temporal dynamics matrix (Vandermonde matrix).</p> </li> <li> <code>xi</code>               (<code>ndarray</code>)           \u2013            <p>Amlitudes of the singular values of the input matrix.</p> </li> <li> <code>_Y</code>               (<code>ndarray</code>)           \u2013            <p>Data snaphot from time step 2 to n (for xi comp.).</p> </li> </ul> References <ol> <li> <p>Schmid, P. (2022). Dynamic Mode Decomposition and Its Variants. 54(1), pp.225-254. doi:10.1146/annurev-fluid-030121-015835.\u00a0\u21a9</p> </li> </ol> <p>Methods:</p> <ul> <li> <code>fit</code>             \u2013              <p>Fit the DMD model to the input X.</p> </li> <li> <code>predict</code>             \u2013              <p>Predict future values using the trained DMD model.</p> </li> </ul>"},{"location":"reference/functions/dmd/#functions.dmd.DMD(r)","title":"<code>r</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Number of modes to keep. If 0 (default), all modes are kept.</p>"},{"location":"reference/functions/dmd/#functions.dmd.DMD.fit","title":"fit","text":"<pre><code>fit(X: ndarray, Y: Union[ndarray, None] = None)\n</code></pre> <p>Fit the DMD model to the input X.</p> <p>Parameters:</p>"},{"location":"reference/functions/dmd/#functions.dmd.DMD.fit(X)","title":"<code>X</code>","text":"(<code>ndarray</code>)           \u2013            <p>Input X matrix of shape (n, m), where m is the number of variables and n is the number of time steps.</p>"},{"location":"reference/functions/dmd/#functions.dmd.DMD.fit(Y)","title":"<code>Y</code>","text":"(<code>Union[ndarray, None]</code>, default:                   <code>None</code> )           \u2013            <p>The output snapshot matrix of shape (n, m).</p>"},{"location":"reference/functions/dmd/#functions.dmd.DMD.predict","title":"predict","text":"<pre><code>predict(x: ndarray, forecast: int = 1) -&gt; ndarray\n</code></pre> <p>Predict future values using the trained DMD model.</p> <p>Args: x: numpy.ndarray of shape (m,) forecast: int     Number of steps to predict into the future.</p> <p>Returns:</p> <ul> <li> <code>predictions</code> (              <code>ndarray</code> )          \u2013            <p>Predicted data matrix for the specified number of prediction steps.</p> </li> </ul>"},{"location":"reference/functions/dmd/#functions.dmd.DMDwC","title":"DMDwC","text":"<pre><code>DMDwC(r: int, B: Union[ndarray, None] = None)\n</code></pre> <p>               Bases: <code>DMD</code></p> <p>Methods:</p> <ul> <li> <code>predict</code>             \u2013              <p>Predict future values using the trained DMD model.</p> </li> </ul>"},{"location":"reference/functions/dmd/#functions.dmd.DMDwC.predict","title":"predict","text":"<pre><code>predict(\n    x: ndarray,\n    forecast: int = 1,\n    U: Union[ndarray, None] = None,\n) -&gt; ndarray\n</code></pre> <p>Predict future values using the trained DMD model.</p> <ul> <li>forecast: int     Number of steps to predict into the future.</li> </ul> <ul> <li>predictions: numpy.ndarray     Predicted data matrix for the specified number of prediction steps.</li> </ul>"},{"location":"reference/functions/metrics/","title":"metrics","text":""},{"location":"reference/functions/metrics/#functions.metrics","title":"metrics","text":"<p>This module is modified part of evaluation from library tsad</p> <p>Functions:</p> <ul> <li> <code>check_errors</code>             \u2013              <p>Check format of input true data.</p> </li> <li> <code>chp_score</code>             \u2013              <p>Calculates various metrics for evaluating anomaly or changepoint detection.</p> </li> <li> <code>extract_cp_confusion_matrix</code>             \u2013              <p>Extracts the confusion matrix for change point detection.</p> </li> <li> <code>filter_detecting_boundaries</code>             \u2013              <p>Filters out empty sublists from a list of detecting boundaries.</p> </li> <li> <code>my_scale</code>             \u2013              <p>ts - segment on which the window is applied</p> </li> <li> <code>single_average_delay</code>             \u2013              <p>anomaly_window_destination: 'lefter', 'righter', 'center'. Default='right'</p> </li> <li> <code>single_detecting_boundaries</code>             \u2013              <p>Extract detecting_boundaries from series or list of timestamps</p> </li> <li> <code>single_evaluate_nab</code>             \u2013              <p>Evaluate the NAB (Numenta Anomaly Benchmark) score for a given set of predictions.</p> </li> </ul>"},{"location":"reference/functions/metrics/#functions.metrics.check_errors","title":"check_errors","text":"<pre><code>check_errors(my_list)\n</code></pre> <p>Check format of input true data.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>int</code>          \u2013            <p>Depth of list, or variant of processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>Exception</code>             \u2013            <p>If non-uniform data format is found at any level.</p> </li> </ul>"},{"location":"reference/functions/metrics/#functions.metrics.check_errors(my_list)","title":"<code>my_list</code>","text":"(<code>list</code>)           \u2013            <p>Uniform format of true data (See evaluate.evaluate).</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score","title":"chp_score","text":"<pre><code>chp_score(\n    true,\n    prediction,\n    metric=\"nab\",\n    window_width=None,\n    portion=0.1,\n    anomaly_window_destination=\"lefter\",\n    clear_anomalies_mode=True,\n    intersection_mode=\"cut right window\",\n    table_of_coef=None,\n    scale_func=\"improved\",\n    scale_koef=1,\n    verbose=False,\n)\n</code></pre> <p>Calculates various metrics for evaluating anomaly or changepoint detection.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li>           \u2013            <p>tuple or dict: Value of the metrics depending on the chosen metric. - 'nab': dict with keys 'Standard', 'LowFP', 'LowFN' and corresponding float values. - 'average_time': tuple with average time (float), missing changepoints (int), false positives (int), number of true changepoints (int). - 'binary': tuple with F1 metric (float), false alarm rate (float), missing alarm rate (float). - 'confusion_matrix': tuple with true positives (int), true negatives (int), false positives (int), false negatives (int).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; y_true = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n</code></pre> <pre><code>&gt;&gt;&gt; y_pre1 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n&gt;&gt;&gt; y_pre2 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n&gt;&gt;&gt; y_pre3 = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n&gt;&gt;&gt; y_pre4 = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n&gt;&gt;&gt; y_pre5 = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n</code></pre> <pre><code>&gt;&gt;&gt; def convert_comp(y):\n...     y_ = pd.Series(y)\n...     y_.index = pd.to_datetime(y_.index, unit=\"s\")\n...     return y_\n</code></pre> <pre><code>&gt;&gt;&gt; y_true_ = convert_comp(y_true)\n&gt;&gt;&gt; for y_pred in [y_pre1, y_pre2, y_pre3, y_pre4, y_pre5]:\n...     print(f\"{y_true}{y_pred}\")\n...     y_pred = convert_comp(y_pred)\n...     print(\"=== Binary ===\")\n...     print(chp_score(\n...         y_true_,\n...         y_pred,\n...         metric=\"binary\",\n...     ))\n...     print(\"=== Average time ===\")\n...     print(chp_score(\n...         y_true_,\n...         y_pred,\n...         metric=\"average_time\",\n...         window_width=\"3s\",\n...         anomaly_window_destination=\"righter\",\n...         portion=1,\n...     ))\n...     print(\"=== NAB ===\")\n...     print(chp_score(\n...         y_true_,\n...         y_pred,\n...         metric=\"nab\",\n...         window_width=\"3s\",\n...         anomaly_window_destination=\"righter\",\n...         portion=1,\n...     ))\n[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0][0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n=== Binary ===\n(0.0, 0.0, 100.0)\n=== Average time ===\n(nan, 1, 0, 1)\n=== NAB ===\n{'Standard': 0.0, 'LowFP': 0.0, 'LowFN': 0.0}\n[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0][0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n=== Binary ===\n(0.0, 16.67, 100.0)\n=== Average time ===\n(Timedelta('0 days 00:00:03'), 0, 0, 1)\n=== NAB ===\n{'Standard': 44.5, 'LowFP': 39.0, 'LowFN': 63.0}\n[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0][1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n=== Binary ===\n(0.0, 16.67, 100.0)\n=== Average time ===\n(nan, 1, 1, 1)\n=== NAB ===\n{'Standard': -5.5, 'LowFP': -11.0, 'LowFN': -3.67}\n[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0][1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n=== Binary ===\n(0.25, 100.0, 0.0)\n=== Average time ===\n(Timedelta('0 days 00:00:00'), 0, 3, 1)\n=== NAB ===\n{'Standard': 83.5, 'LowFP': 67.0, 'LowFN': 89.0}\n[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0][0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n=== Binary ===\n(1.0, 0.0, 0.0)\n=== Average time ===\n(Timedelta('0 days 00:00:00'), 0, 0, 1)\n=== NAB ===\n{'Standard': 100.0, 'LowFP': 100.0, 'LowFN': 100.0}\n</code></pre>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(true)","title":"<code>true</code>","text":"(<code>Series or list</code>)           \u2013            <p>True labels of anomalies or changepoints. Can be in various formats: - pd.Series with binary int labels (1 is anomaly, 0 is not anomaly) - list of pd.Timestamp of true labels - list of list of t1, t2: left and right detection boundaries of pd.Timestamp - list of pd.Series with binary int labels for multiple datasets - list of list of pd.Timestamp of true labels for multiple datasets - list of list of list of t1, t2: left and right detection boundaries of pd.Timestamp for multiple datasets</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(prediction)","title":"<code>prediction</code>","text":"(<code>Series or list</code>)           \u2013            <p>Predicted labels of anomalies or changepoints. Can be in various formats: - pd.Series with binary int labels (1 is anomaly, 0 is not anomaly) - list of pd.Series with binary int labels for multiple datasets</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(metric)","title":"<code>metric</code>","text":"(<code>str</code>, default:                   <code>'nab'</code> )           \u2013            <p>Metric to use for evaluation. Options are {'nab', 'binary', 'average_time', 'confusion_matrix'}. Default is 'nab'.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(window_width)","title":"<code>window_width</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Width of detection window as a pd.Timedelta string. Default is None.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(portion)","title":"<code>portion</code>","text":"(<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Portion of the width of the length of prediction divided by the number of real CPs in the dataset. Default is 0.1.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(anomaly_window_destination)","title":"<code>anomaly_window_destination</code>","text":"(<code>str</code>, default:                   <code>'lefter'</code> )           \u2013            <p>Location of the detection window relative to the anomaly. Options are {'lefter', 'righter', 'center'}. Default is 'lefter'.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(clear_anomalies_mode)","title":"<code>clear_anomalies_mode</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, only the first value inside the detection window is taken. If False, only the last value inside the detection window is taken. Default is True.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(intersection_mode)","title":"<code>intersection_mode</code>","text":"(<code>str</code>, default:                   <code>'cut right window'</code> )           \u2013            <p>How to handle overlapping detection windows. Options are {'cut left window', 'cut right window', 'both'}. Default is 'cut right window'.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(table_of_coef)","title":"<code>table_of_coef</code>","text":"(<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Application profiles of NAB metric. Default is None.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(scale_func)","title":"<code>scale_func</code>","text":"(<code>str</code>, default:                   <code>'improved'</code> )           \u2013            <p>Scoring function in NAB metric. Options are {'default', 'improved'}. Default is 'improved'.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(scale_koef)","title":"<code>scale_koef</code>","text":"(<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Smoothing factor for the scoring function. Default is 1.</p>"},{"location":"reference/functions/metrics/#functions.metrics.chp_score(verbose)","title":"<code>verbose</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, outputs useful information. Default is False.</p>"},{"location":"reference/functions/metrics/#functions.metrics.extract_cp_confusion_matrix","title":"extract_cp_confusion_matrix","text":"<pre><code>extract_cp_confusion_matrix(\n    detecting_boundaries, prediction, point=0, binary=False\n)\n</code></pre> <p>Extracts the confusion matrix for change point detection.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>A dictionary containing: - 'TPs' (dict): Dictionary of true positives with window indices as keys and lists of [start, predicted, end] times as values. - 'FPs' (list): List of false positive timestamps. - 'FNs' (list): List of false negative window indices or timestamps.</p> </li> </ul>"},{"location":"reference/functions/metrics/#functions.metrics.extract_cp_confusion_matrix(detecting_boundaries)","title":"<code>detecting_boundaries</code>","text":"(<code>list of list of int</code>)           \u2013            <p>List of pairs of start and end times for detecting boundaries.</p>"},{"location":"reference/functions/metrics/#functions.metrics.extract_cp_confusion_matrix(prediction)","title":"<code>prediction</code>","text":"(<code>Series</code>)           \u2013            <p>Series containing the prediction results with timestamps.</p>"},{"location":"reference/functions/metrics/#functions.metrics.extract_cp_confusion_matrix(point)","title":"<code>point</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Index of the predicted change point within the window. Defaults to 0.</p>"},{"location":"reference/functions/metrics/#functions.metrics.extract_cp_confusion_matrix(binary)","title":"<code>binary</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Flag indicating whether to use binary classification. Defaults to False.</p>"},{"location":"reference/functions/metrics/#functions.metrics.filter_detecting_boundaries","title":"filter_detecting_boundaries","text":"<pre><code>filter_detecting_boundaries(detecting_boundaries)\n</code></pre> <p>Filters out empty sublists from a list of detecting boundaries.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li>           \u2013            <p>list of list: A list containing only the non-empty sublists from the input.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filter_detecting_boundaries([[1, 2], [], [1, 2]])\n[[1, 2], [1, 2]]\n</code></pre> <pre><code>&gt;&gt;&gt; filter_detecting_boundaries([[], []])\n[]\n</code></pre>"},{"location":"reference/functions/metrics/#functions.metrics.filter_detecting_boundaries(detecting_boundaries)","title":"<code>detecting_boundaries</code>","text":"(<code>list of list</code>)           \u2013            <p>A list containing sublists,                                  where each sublist represents a boundary.</p>"},{"location":"reference/functions/metrics/#functions.metrics.my_scale","title":"my_scale","text":"<pre><code>my_scale(\n    fp_case_window=None,\n    A_tp=1,\n    A_fp=0,\n    koef=1,\n    detalization=1000,\n    clear_anomalies_mode=True,\n    plot_figure=False,\n)\n</code></pre> <p>ts - segment on which the window is applied</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_average_delay","title":"single_average_delay","text":"<pre><code>single_average_delay(\n    detecting_boundaries,\n    prediction,\n    anomaly_window_destination,\n    clear_anomalies_mode,\n)\n</code></pre> <p>anomaly_window_destination: 'lefter', 'righter', 'center'. Default='right'</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_detecting_boundaries","title":"single_detecting_boundaries","text":"<pre><code>single_detecting_boundaries(\n    true_series,\n    true_list_ts,\n    prediction,\n    portion,\n    window_width,\n    anomaly_window_destination,\n    intersection_mode,\n)\n</code></pre> <p>Extract detecting_boundaries from series or list of timestamps</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab","title":"single_evaluate_nab","text":"<pre><code>single_evaluate_nab(\n    detecting_boundaries,\n    prediction,\n    table_of_coef=None,\n    clear_anomalies_mode=True,\n    scale_func=\"improved\",\n    scale_koef=1,\n) -&gt; ndarray\n</code></pre> <p>Evaluate the NAB (Numenta Anomaly Benchmark) score for a given set of predictions.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>numpy.ndarray: A 3xN array where N is the number of profiles ('Standard', 'LowFP', 'LowFN'). The first row contains the scores, the second row contains the null scores, and the third row contains the perfect scores.</p> </li> </ul>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(detecting_boundaries)","title":"<code>detecting_boundaries</code>","text":"(<code>list of list of two float values</code>)           \u2013            <p>The list of lists of left and right boundary indices for scoring results of labeling. If empty, can be [[]], or [[],[t1,t2],[]].</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(prediction)","title":"<code>prediction</code>","text":"(<code>list</code>)           \u2013            <p>The list of predicted anomaly points.</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(table_of_coef)","title":"<code>table_of_coef</code>","text":"(<code>pandas DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Table of coefficients for NAB score function. Default is a 3x4 DataFrame with indices 'Standard', 'LowFP', 'LowFN' and columns 'A_tp', 'A_fp', 'A_tn', 'A_fn'.</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(clear_anomalies_mode)","title":"<code>clear_anomalies_mode</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, the left of Atp boundary is equal to the right of Afp. Otherwise, fault mode, when the left of Afp boundary is the right of Atp. Default is True.</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(scale_func)","title":"<code>scale_func</code>","text":"(<code>str</code>, default:                   <code>'improved'</code> )           \u2013            <p>The scaling function to use. Default is \"improved\". If not \"improved\", an exception is raised.</p>"},{"location":"reference/functions/metrics/#functions.metrics.single_evaluate_nab(scale_koef)","title":"<code>scale_koef</code>","text":"(<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The scaling coefficient. Default is 1. 1 - depends on the relative step, which means that if there are too many points in the scoring window, the difference will be too large. too many points in the scoring window, the drop will be too stiff in the middle. 2- the leftmost point is not equal to Atp and the right is not equal to Afp. (especially if you use a blurring multiplier).</p>"},{"location":"reference/functions/plot/","title":"plot","text":""},{"location":"reference/functions/plot/#functions.plot","title":"plot","text":"<p>Functions:</p> <ul> <li> <code>plot_chd</code>             \u2013              <p>Plot hange-Point Detection Results.</p> </li> <li> <code>set_size</code>             \u2013              <p>Set figure dimensions to avoid scaling in LaTeX.</p> </li> </ul>"},{"location":"reference/functions/plot/#functions.plot.plot_chd","title":"plot_chd","text":"<pre><code>plot_chd(\n    datas: dict[str, ndarray | None] | list[ndarray | None],\n    y_true: list[float] | ndarray | None = None,\n    labels: list[str] | None = None,\n    idx_start: int | None = None,\n    idx_end: int | None = None,\n    ids_in_start: list[int] | None = None,\n    ids_in_end: list[int] | None = None,\n    grace_period: int | None = None,\n    normalize: bool = False,\n    axs: ndarray | None = None,\n    **fig_kwargs: dict,\n)\n</code></pre> <p>Plot hange-Point Detection Results.</p> <p>Parameters:</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(datas)","title":"<code>datas</code>","text":"(<code>dict[str, ndarray | None] | list[ndarray | None]</code>)           \u2013            <p>List of data to plot. Each data is plot on a separate subplot.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(y_true)","title":"<code>y_true</code>","text":"(<code>list[float] | ndarray | None</code>, default:                   <code>None</code> )           \u2013            <p>True change-point locations. Plotted as vertical lines.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(labels)","title":"<code>labels</code>","text":"(<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>List of labels for each data.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(idx_start)","title":"<code>idx_start</code>","text":"(<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Starting index to plot. Plot from the beginning if None.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(idx_end)","title":"<code>idx_end</code>","text":"(<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Ending index to plot. Plot till the end if None.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(idx_in_start)","title":"<code>idx_in_start</code>","text":"\u2013            <p>Starting index for inlay plot. No inlay plot if None.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(idx_in_end)","title":"<code>idx_in_end</code>","text":"\u2013            <p>Ending index for inlay plot. No inlay plot if None.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(grace_period)","title":"<code>grace_period</code>","text":"(<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Grace period for change-point. Plots grayed out region where peak of detection could be expected.</p>"},{"location":"reference/functions/plot/#functions.plot.plot_chd(normalize)","title":"<code>normalize</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Normalize data. If False, no normalization is done.</p>"},{"location":"reference/functions/plot/#functions.plot.set_size","title":"set_size","text":"<pre><code>set_size(\n    width: (\n        float | int | Literal[\"article\", \"thesis\", \"beamer\"]\n    ) = 307.28987,\n    fraction=1.0,\n    subplots=(1, 1),\n)\n</code></pre> <p>Set figure dimensions to avoid scaling in LaTeX.</p>"},{"location":"reference/functions/plot/#functions.plot.set_size--parameters","title":"Parameters","text":"<p>width: float or string         Document width in points, or string of predined document type fraction: float, optional         Fraction of the height which you wish the figure to occupy subplots: array-like, optional         The number of rows and columns of subplots. Returns</p> <p>fig_dim: tuple         Dimensions of figure in inches</p>"},{"location":"reference/functions/preprocessing/","title":"preprocessing","text":""},{"location":"reference/functions/preprocessing/#functions.preprocessing","title":"preprocessing","text":"<p>Classes:</p> <ul> <li> <code>Hankelizer</code>           \u2013            <p>Mini-batch Hankelizer that keeps track of the transformation.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>hankel</code>             \u2013              <p>Create a Hankel matrix from a given input array.</p> </li> </ul>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.Hankelizer","title":"Hankelizer","text":"<pre><code>Hankelizer(\n    w: int = 2,\n    return_partial: bool | Literal[\"copy\"] = \"copy\",\n)\n</code></pre> <p>               Bases: <code>Hankelizer</code></p> <p>Mini-batch Hankelizer that keeps track of the transformation.</p> <p>Similar to the original Hankelizer, it The _memory_usage differs from the original Hankelizer due to storing the transformation track which can be significant for large datasets.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>transform_track</code>               (<code>list[dict]</code>)           \u2013            <p>The transformation track.</p> </li> </ul> <p>Examples:</p> <p>Using Mini-batch Hankelizer is equivalent to</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from river.preprocessing import Hankelizer as H\n&gt;&gt;&gt; X_train = pd.DataFrame(np.random.rand(10, 2), columns=[\"a\", \"b\"])\n&gt;&gt;&gt; hn = 3\n&gt;&gt;&gt; hankelizer = Hankelizer(hn)\n&gt;&gt;&gt; hankelizer_old = H(hn)\n</code></pre> <pre><code>&gt;&gt;&gt; hankelizer.learn_many(X_train)\n&gt;&gt;&gt; X_t_new = hankelizer.transform_many(X_train)\n&gt;&gt;&gt; X_t_old_ = []\n&gt;&gt;&gt; for j, x in enumerate(X_train.to_dict(orient=\"records\")):\n...     hankelizer_old.learn_one(x)\n...     X_t_old_.append(hankelizer_old.transform_one(x))\n&gt;&gt;&gt; X_t_old = pd.DataFrame(X_t_old_)\n&gt;&gt;&gt; X_t_new.equals(X_t_old)\nTrue\n</code></pre> <p>Calling transform_many first produces consistent behavior</p> <pre><code>&gt;&gt;&gt; hankelizer = Hankelizer(hn)\n&gt;&gt;&gt; X_t_first = hankelizer.transform_many(X_train)\n&gt;&gt;&gt; X_t_first.equals(X_t_new)\nTrue\n</code></pre>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.Hankelizer(w)","title":"<code>w</code>","text":"(<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The window size.</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.Hankelizer(return_partial)","title":"<code>return_partial</code>","text":"(<code>bool | Literal['copy']</code>, default:                   <code>'copy'</code> )           \u2013            <p>Whether to return the partial Hankel matrix.</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.hankel","title":"hankel","text":"<pre><code>hankel(\n    X: ndarray | DataFrame,\n    hn: int,\n    step: int = 1,\n    return_partial: bool | Literal[\"copy\"] = \"copy\",\n) -&gt; ndarray | DataFrame\n</code></pre> <p>Create a Hankel matrix from a given input array.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray | DataFrame</code>           \u2013            <p>np.ndarray: The Hankel matrix.</p> </li> </ul> TODO <ul> <li> Add support for 2D arrays.</li> </ul> Example <p>X = np.array([1., 2., 3., 4., 5.]) hankel(X, 3) array([[1., 1., 1.],     [1., 1., 2.],     [1., 2., 3.],     [2., 3., 4.],     [3., 4., 5.]]) hankel(X, 3, return_partial=False) array([[1., 2., 3.],     [2., 3., 4.],     [3., 4., 5.]]) X = np.array([[1., 2., 3., 4., 5.], [9., 8., 7., 6., 5.]]).T hankel(X, 3, return_partial=True) array([[nan, nan, nan, nan,  1.,  9.],     [nan, nan,  1.,  9.,  2.,  8.],     [ 1.,  9.,  2.,  8.,  3.,  7.],     [ 2.,  8.,  3.,  7.,  4.,  6.],     [ 3.,  7.,  4.,  6.,  5.,  5.]]) X = np.array([[1.0, 2.0, 3.0, 4.0, 5.0], [9.0, 8.0, 7.0, 6.0, 5.0]]).T hankel(X, 3, 2, return_partial=True) array([[nan, nan, nan, nan,  3.,  7.],     [nan, nan,  2.,  8.,  4.,  6.],     [ 1.,  9.,  3.,  7.,  5.,  5.],     [ 2.,  8.,  4.,  6.,  1.,  9.],     [ 3.,  7.,  5.,  5.,  2.,  8.]])</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.hankel(X)","title":"<code>X</code>","text":"(<code>ndarray</code>)           \u2013            <p>The input array.</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.hankel(hn)","title":"<code>hn</code>","text":"(<code>int</code>)           \u2013            <p>The number of columns in the Hankel matrix.</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.hankel(step)","title":"<code>step</code>","text":"(<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The step size for the delays. Defaults to 1.</p>"},{"location":"reference/functions/preprocessing/#functions.preprocessing.hankel(cut_rollover)","title":"<code>cut_rollover</code>","text":"(<code>bool</code>)           \u2013            <p>Whether to cut the rollover part of the Hankel matrix. Defaults to True.</p>"},{"location":"reference/functions/rolling/","title":"rolling","text":""},{"location":"reference/functions/rolling/#functions.rolling","title":"rolling","text":"<p>Classes:</p> <ul> <li> <code>Rolling</code>           \u2013            <p>A generic wrapper for performing rolling computations.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>separate_args_kwargs</code>             \u2013              <p>Separate args and kwargs from a list of tuples.</p> </li> </ul>"},{"location":"reference/functions/rolling/#functions.rolling.Rolling","title":"Rolling","text":"<pre><code>Rolling(obj, window_size)\n</code></pre> <p>               Bases: <code>Rolling</code></p> <p>A generic wrapper for performing rolling computations.</p> <p>This can be wrapped around any object which implements both an <code>update</code> and a <code>revert</code> method. Inputs to <code>update</code> are stored in a queue. Elements of the queue are popped when the window is full.</p> <p>Parameters:</p> <p>Examples:</p> <p>For instance, here is how you can compute a rolling average over a window of size 3:</p> <pre><code>&gt;&gt;&gt; np.random.seed(0)\n&gt;&gt;&gt; r = 1\n&gt;&gt;&gt; m = 2\n&gt;&gt;&gt; n = 5\n&gt;&gt;&gt; X = pd.DataFrame(np.linalg.qr(np.random.randn(n, m))[0])\n&gt;&gt;&gt; from river.decomposition import OnlineSVD\n</code></pre> <pre><code>&gt;&gt;&gt; svd = Rolling(OnlineSVD(n_components=r, initialize=5, seed=0), window_size=5)\n&gt;&gt;&gt; rsvd = Rolling(OnlineSVD(n_components=r, initialize=5, seed=0), window_size=5)\n</code></pre> <pre><code>&gt;&gt;&gt; for x in X.to_dict(orient='records'):\n...     rsvd.update(x=x)\n&gt;&gt;&gt; svd.update_many(x=X)\n&gt;&gt;&gt; svd.n_seen == rsvd.n_seen\nTrue\n&gt;&gt;&gt; np.abs(svd.transform_one(x)[0]) == np.abs(rsvd.transform_one(x)[0])\nTrue\n&gt;&gt;&gt; X = pd.DataFrame(np.linalg.qr(np.random.randn(2, m))[0])\n&gt;&gt;&gt; for x in X.to_dict(orient='records'):\n...     rsvd.update(x=x)\n&gt;&gt;&gt; svd.update_many(x=X)\n&gt;&gt;&gt; np.abs(svd.transform_one(x)[0]) == np.abs(rsvd.transform_one(x)[0])\nTrue\n</code></pre>"},{"location":"reference/functions/rolling/#functions.rolling.Rolling(obj)","title":"<code>obj</code>","text":"\u2013            <p>An object that implements both an <code>update</code> method and a <code>rolling</code> method.</p>"},{"location":"reference/functions/rolling/#functions.rolling.Rolling(window_size)","title":"<code>window_size</code>","text":"\u2013            <p>Size of the window.</p>"},{"location":"reference/functions/rolling/#functions.rolling.separate_args_kwargs","title":"separate_args_kwargs","text":"<pre><code>separate_args_kwargs(list_of_tuples)\n</code></pre> <p>Separate args and kwargs from a list of tuples.</p> <p>Imagine transposing a list of tuples. This function separates list of args and kwargs tuples and makes args and kwargs containing most compatible iterables.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; separate_args_kwargs(\n...     [((1, 2), {'x': 3, 'y': 4}), ((5, 6), {'x': 8, 'y': 9})])\n([[1, 5], [2, 6]], {'x': [3, 8], 'y': [4, 9]})\n&gt;&gt;&gt; separate_args_kwargs(\n...     [((np.array([1, 2 ]),), {'x': np.array([3,  4]), 'y': np.array([5,  6])}),\n...     ((np.array([ 2, 3]),), {'x': np.array([4, 5]), 'y': np.array([6 , 7])})])\n([array([[1, 2],\n    [2, 3]])], {'x': array([[3, 4],\n    [4, 5]]), 'y': array([[5, 6],\n    [6, 7]])})\n&gt;&gt;&gt; separate_args_kwargs(\n...     [(({'a': 1, 'b': 2},), {'x': {'a': 3, 'b': 4}, 'y': {'a': 5, 'b': 6}}),\n...     (({'a': 7, 'b': 8},), {'x': {'a': 7, 'b': 8}, 'y': {'a': 7, 'b': 8}})])\n([   a  b\n0  1  2\n1  7  8], {'x':    a  b\n0  3  4\n1  7  8, 'y':    a  b\n0  5  6\n1  7  8})\n</code></pre>"}]}